{"cells":[{"cell_type":"markdown","metadata":{"id":"gwxAV9V2be6W"},"source":["# **Deblurring DRED**\n","\n","---\n","\n","This code is mainly based on DeepRED code available at https://github.com/GaryMataev/DeepRED with some small changes."]},{"cell_type":"markdown","metadata":{"id":"L0EnVO3Cbe6a"},"source":["# Import libs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8273,"status":"ok","timestamp":1629968942593,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"ohameJIJbe6b"},"outputs":[],"source":["import os\n","from threading import Thread  # needed since the denoiser is running in parallel\n","import queue\n","\n","import numpy as np\n","import torch\n","import torch.optim\n","from models.skip import skip  # our network\n","\n","from utils.utils import *  # auxiliary functions\n","from utils.mine_blur_utils2 import *  # blur functions\n","from utils.data import Data  # class that holds img, psnr, time\n","\n","from skimage.restoration import denoise_nl_means\n","\n","from scipy.signal import convolve2d"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1629968942594,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"WHkR4Phrbe6d"},"outputs":[],"source":["# got GPU? - if you are not getting the exact article results set CUDNN to False\n","CUDA_FLAG = True\n","CUDNN = True \n","if CUDA_FLAG:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    # GPU accelerated functionality for common operations in deep neural nets\n","    torch.backends.cudnn.enabled = CUDNN\n","    # benchmark mode is good whenever your input sizes for your network do not vary.\n","    # This way, cudnn will look for the optimal set of algorithms for that particular \n","    # configuration (which takes some time). This usually leads to faster runtime.\n","    # But if your input sizes changes at each iteration, then cudnn will benchmark every\n","    # time a new size appears, possibly leading to worse runtime performances.\n","    torch.backends.cudnn.benchmark = CUDNN\n","    # torch.backends.cudnn.deterministic = True\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor"]},{"cell_type":"markdown","metadata":{"id":"aarek5Vsbe6e"},"source":["# Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":220,"status":"ok","timestamp":1629972770034,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"H40Sa2xEbe6f"},"outputs":[],"source":["NOISE_SIGMA = 5\n","STD_BLUR    = 1.6\n","DIM_FILTER  = 21\n","BLUR_TYPE = 'gauss_blur'  # 'gauss_blur' or 'uniform_blur' that the two only options\n","GRAY_SCALE = False  # if gray scale is False means we have rgb image, the psnr will be compared on Y. ch.\n","                    # if gray scale is True it will turn rgb to gray scale\n","USE_FOURIER = False\n","\n","# graphs labels:\n","X_LABELS = ['Iterations']*3\n","Y_LABELS = ['PSNR between x and net (db)', 'PSNR with original image (db)', 'loss']\n","\n","# Algorithm NAMES (to get the relevant image: use data_dict[alg_name].img)\n","# for example use data_dict['Clean'].img to get the clean image\n","ORIGINAL  = 'Clean'\n","CORRUPTED = 'Blurred'\n","DIP_NLM   = 'DRED (NLM)'"]},{"cell_type":"markdown","metadata":{"id":"22r18Xddbe6g"},"source":["# Load image for DeBlurring"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1629972772292,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"k0zWSk8Ibe6g"},"outputs":[],"source":["def load_imgs_deblurring(fname, blur_type, noise_sigma,STD_BLUR, DIM_FILTER,plot=False):\n","    \"\"\"  Loads an image, and add gaussian blur\n","    Args: \n","         fname: path to the image\n","         blur_type: 'uniform' or 'gauss'\n","         noise_sigma: noise added after blur\n","         covert2gray: should we convert to gray scale image?\n","         plot: will plot the images\n","    Out:\n","         dictionary of images and dictionary of psnrs\n","    \"\"\"\n","    img_pil, img_np = load_and_crop_image(fname)        \n","    if GRAY_SCALE:\n","        img_np = rgb2gray(img_pil)\n","    kernel = get_h(blur_type,STD_BLUR,DIM_FILTER)\n","    kernel_torch = np_to_torch(kernel)  \n","    blurred = torch_to_np(blur_th(np_to_torch(img_np), kernel_torch))\n","    blurred = np.clip(blurred + np.random.normal(scale=noise_sigma/255., size=blurred.shape), 0, 1).astype(np.float32)\n","    data_dict = { ORIGINAL: Data(img_np), \n","                 CORRUPTED: Data(blurred, compare_PSNR(img_np, blurred,   on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)) }\n","    if plot:\n","        plot_dict(data_dict)\n","    return data_dict,kernel_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":970},"executionInfo":{"elapsed":2217,"status":"ok","timestamp":1629972783829,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"4roj0RCvbe6h","outputId":"745b3a09-aab0-4aa2-ec9a-3161008c923c"},"outputs":[],"source":["# Get the LR and HR images\n","data_dict,kernel_torch = load_imgs_deblurring('datasets/watercastle.png', BLUR_TYPE, NOISE_SIGMA,STD_BLUR, DIM_FILTER, plot=True)"]},{"cell_type":"markdown","metadata":{"id":"-AIznm_jbe6i"},"source":["# THE NETWORK"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1629972784029,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"BV2FwA0kbe6i"},"outputs":[],"source":["def get_network_and_input(img_shape, input_depth=32, pad='reflection',\n","                          upsample_mode='bilinear', use_interpolate=True, align_corners=False,\n","                          act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128, skip_n11=4,\n","                          num_scales=5, downsample_mode='stride', INPUT='noise'):  # 'meshgrid'\n","    \"\"\" Getting the relevant network and network input (based on the image shape and input depth)\n","        We are using the same default params as in DIP article\n","        img_shape - the image shape (ch, x, y)\n","    \"\"\"\n","    n_channels = img_shape[0]\n","    net = skip(input_depth, n_channels,\n","               num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n","               num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n","               num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n","               upsample_mode=upsample_mode, use_interpolate=use_interpolate, align_corners=align_corners,\n","               downsample_mode=downsample_mode, need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun).type(dtype)\n","    net_input = get_noise(input_depth, INPUT, img_shape[1:]).type(dtype).detach()\n","    return net, net_input"]},{"cell_type":"markdown","metadata":{"id":"2wdNbLWhbe6j"},"source":["## Non Local Means denoiser"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1629972784996,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"0ZZr7Ilzbe6k"},"outputs":[],"source":["def non_local_means(noisy_np_img, sigma, fast_mode=True):\n","    \"\"\" get a numpy noisy image\n","        returns a denoised numpy image using Non-Local-Means\n","    \"\"\" \n","    sigma = sigma / 255.\n","    h = 0.6 * sigma if fast_mode else 0.8 * sigma\n","    patch_kw = dict(h=h,                   # Cut-off distance, a higher h results in a smoother image\n","                    sigma=sigma,           # sigma provided\n","                    fast_mode=fast_mode,   # If True, a fast version is used. If False, the original version is used.\n","                    patch_size=5,          # 5x5 patches (Size of patches used for denoising.)\n","                    patch_distance=6,      # 13x13 search area\n","                    multichannel=False)\n","    denoised_img = []\n","    n_channels = noisy_np_img.shape[0]\n","    for c in range(n_channels):\n","        denoise_fast = denoise_nl_means(noisy_np_img[c, :, :], **patch_kw)\n","        denoised_img += [denoise_fast]\n","    return np.array(denoised_img, dtype=np.float32)"]},{"cell_type":"markdown","metadata":{"id":"J9BP7LcUPLBQ"},"source":["#  ESTIMATING THE NOISE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1629972785926,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"IiDKiaosPCUr","outputId":"279b7172-6af1-475a-b1bb-d789d59096ea"},"outputs":[],"source":["lap_kernel = np.array([[1,-2,1], [-2, 4, -2], [1,-2,1]])\n","h=data_dict[CORRUPTED].img[:,:,:].shape[2]\n","w=data_dict[CORRUPTED].img[:,:,:].shape[1]\n","\n","def estimate_variance(img):\n","  out = convolve2d(img, lap_kernel, mode='valid')\n","  out = np.sum(np.abs(out))\n","  out = (out*np.sqrt(0.5*np.pi)/(6*(h-2)*(w-2)))\n","  return out\n","\n","print(data_dict[CORRUPTED].img[:,:,:].shape)\n","NOISE_SIGMA = estimate_variance(data_dict[CORRUPTED].img[0,:,:])*255\n","print(NOISE_SIGMA)"]},{"cell_type":"markdown","metadata":{"id":"az_90AaSbe6l"},"source":["# Deep Image prior via ADMM with RED"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1629975470195,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"ZoE2KVtbbe6l"},"outputs":[],"source":["def train_via_admm(net, net_input, denoiser_function, kernel_torch, y, tau, noise_lev,            # H is the kernel, y is the blurred image\n","                   clean_img=None, plot_array={}, algorithm_name=\"\",             # clean_img for psnr to be shown\n","                   gamma=.9, step_size=1000, save_path=\"\",         # scheduler parameters and path to save params\n","                   admm_iter=5000, LR=0.004,                                          # admm_iter is step_2_iter\n","                   sigma_f=3, update_iter=10, method='fixed_point',  # method: 'fixed_point' or 'grad' or 'mixed'\n","                   beta=0.1, mu=0.1, LR_x=None, noise_factor=0.01):  # LR_x needed only if method!=fixed_point\n","    \"\"\" training the network using\n","        # mu=0.04\n","        ## Must Params ##\n","        net                 - the network to be trained\n","        net_input           - the network input\n","        denoiser_function   - an external denoiser function, used as black box, this function\n","                              must get numpy noisy image, and return numpy denoised image\n","        H                   - the blur kernel\n","        y                   - the blurred image\n","        \n","        # optional params #\n","        clean_img           - the original image if exist for psnr compare only, or None (default)\n","        plot_array          - prints params at the begging of the training and plot images at the required indices\n","        algorithm_name      - the name that would show up while running, just to know what we are running ;)\n","        admm_iter           - total number of admm epoch\n","        LR                  - the lr of the network\n","        sigma_f             - the sigma to send the denoiser function\n","        update_iter         - denoised image updated every 'update_iter' iteration\n","        method              - 'fixed_point' or 'grad' or 'mixed' \n","                \n","        # equation params #  \n","        beta                - regularization parameter (lambda in the article)\n","        mu                  - ADMM parameter\n","        LR_x                - learning rate of the parameter x, needed only if method!=fixed point\n","        # more\n","        noise_factor       - the amount of noise added to the input of the network\n","    \"\"\"\n","    # get optimizer and loss function:\n","    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss\n","    # additional noise added to the input:\n","    net_input_saved = net_input.detach().clone()\n","    noise = net_input.detach().clone()\n","\n","    # x update method:\n","    if method == 'fixed_point':\n","        swap_iter = admm_iter + 1\n","        LR_x = None\n","    elif method == 'grad':\n","        swap_iter = -1\n","    elif method == 'mixed':\n","        swap_iter = admm_iter // 2\n","    else:\n","        assert False, \"method can be 'fixed_point' or 'grad' or 'mixed' only \"\n","\n","    # run RED via ADMM, initialize:\n","    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=gamma, step_size=step_size)\n","    y_torch = np_to_torch(y).type(dtype)\n","    x = y.copy()\n","    avg = np.rint(y)\n","    f_x, u = x.copy(), np.zeros_like(x)\n","    img_queue = queue.Queue()\n","    # The denoiser thread that runs in parallel:\n","    denoiser_thread = Thread(target=lambda q, f, f_args: q.put(f(*f_args)),\n","                             args=(img_queue, denoiser_function, [x.copy(), sigma_f]))\n","    denoiser_thread.start()\n","\n","    list_psnr=[]\n","    list_stopping=[]\n","\n","    if clean_img is not None: \n","        psnr_y = compare_PSNR(clean_img, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)  # get the noisy image psnr\n","    \n","    # ADMM:\n","    for i in range(1, 1 + admm_iter):\n","\n","        rho = tau*noise_lev*np.sqrt(y.shape[0]*y.shape[1]*y.shape[2] - 1)\n","        \n","        # step 1, update network:\n","        optimizer.zero_grad()\n","        net_input = net_input_saved + (noise.normal_() * noise_factor)\n","        out = net(net_input)\n","        out_np = torch_to_np(out)\n","        # loss:\n","        loss_y = mse(blur_th(out, kernel_torch), y_torch)\n","        loss_x = mse(out, np_to_torch(x - u).type(dtype))\n","        total_loss = loss_y + mu * loss_x\n","        total_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        # step 2, update x using a denoiser and result from step 1\n","        if i % update_iter == 0:  # the denoiser work in parallel\n","            denoiser_thread.join()\n","            f_x = img_queue.get()\n","            denoiser_thread = Thread(target=lambda q, f, f_args: q.put(f(*f_args)),\n","                                     args=(img_queue, denoiser_function, [x.copy(), sigma_f]))\n","            denoiser_thread.start()\n","\n","        if i < swap_iter:\n","            x = 1 / (beta + mu) * (beta * f_x + mu * (out_np + u))\n","        else:\n","            x = x - LR_x * (beta * (x - f_x) + mu * (x - out_np - u))\n","        np.clip(x, 0, 1, out=x)  # making sure that image is in bounds\n","\n","        # step 3, update u\n","        u = u + out_np - x\n","\n","        # Averaging:\n","        avg = avg * .99 + out_np * .01\n","\n","        stopping = np.sqrt(np.sum(np.square(torch_to_np(blur_th(out.data, kernel_torch))-y)))/ rho \n","        list_stopping.append(stopping)\n","\n","        # show psnrs:\n","        if clean_img is not None:\n","            psnr_net = compare_PSNR(clean_img, out_np, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            psnr_x_u = compare_PSNR(clean_img, x - u, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            psnr_avg = compare_PSNR(clean_img, avg, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            psnr_noisy = compare_PSNR(clean_img, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            list_psnr.append(psnr_avg)\n","            print('\\r', algorithm_name, '%04d/%04d Loss %f' % (i, admm_iter, total_loss.item()),\n","                  'psnrs: noisy: %.2f net: %.2f x-u: %.2f avg: %.2f' % (psnr_noisy,psnr_net, psnr_x_u,psnr_avg), \n","                  'stopping: %.2f' %(stopping), end='')\n","            if i in plot_array:\n","              tmp_dict = {'Clean': Data(clean_img),\n","                          'Blurred': Data(y,psnr_y),\n","                          'Net': Data(out_np, psnr_net),\n","                          'x-u': Data(x - u, psnr_x_u),\n","                          'avg': Data(avg, psnr_avg),\n","                          'u': Data((u - np.min(u)) / (np.max(u) - np.min(u)))\n","                          }\n","              plot_dict(tmp_dict)\n","        else:\n","          print('\\r', algorithm_name, 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')\n","\n","    # join the thread:\n","    if denoiser_thread.is_alive():\n","        denoiser_thread.join()  # joining the thread\n","    return avg, list_psnr,list_stopping"]},{"cell_type":"markdown","metadata":{"id":"yhQ4eAijbe6m"},"source":["## Let's Go:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":693489,"status":"ok","timestamp":1629976168708,"user":{"displayName":"Pasquale Cascarano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiM909NmzdOoi9yvr4dT-GSjnx8iLFZYu3vMZzX_w=s64","userId":"05814425073560268488"},"user_tz":-120},"id":"6tje0Pvrbe6n","outputId":"9613bd21-8b5d-4269-ef1d-2fa24597dc4d"},"outputs":[],"source":["def run_and_plot(denoiser, name, plot_checkpoints={}):\n","    global data_dict\n","    noise_lev = NOISE_SIGMA/255\n","    tau=1\n","    net, net_input = get_network_and_input(img_shape=data_dict[CORRUPTED].img.shape)\n","    clean,list_psnr,list_stopping = train_via_admm(net, net_input, denoiser, kernel_torch, data_dict[CORRUPTED].img, tau, noise_lev, \n","                           algorithm_name=name, plot_array=plot_checkpoints,\n","                           clean_img=data_dict[ORIGINAL].img)\n","    data_dict[name] = Data(clean, compare_PSNR(data_dict[ORIGINAL].img, clean, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n","    plot_dict(data_dict)\n","\n","    return clean,list_psnr,list_stopping\n","\n","\n","plot_checkpoints = {1, 10, 100, 1000, 2000, 5000, 10000, 20000}\n","clean,list_psnr,list_stopping = run_and_plot(non_local_means, DIP_NLM, plot_checkpoints)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"deblurring_DRED.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('PsiDONet22')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"2e600517162b2d52f2381e9f8081dec209e7747d3e7da5b473d1484e44801cd5"}}},"nbformat":4,"nbformat_minor":0}
