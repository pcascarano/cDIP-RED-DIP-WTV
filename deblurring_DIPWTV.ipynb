{"cells":[{"cell_type":"markdown","metadata":{"id":"6rQlzjabmuZI"},"source":["# **Deblurring DIPWTV**\n","\n","---\n","\n","This code is mainly based on DeepRED code available at https://github.com/GaryMataev/DeepRED changing the regularization term as in ADMM-DIPTV code available at https://github.com/sedaboni/ADMM-DIPTV "]},{"cell_type":"markdown","metadata":{"id":"whIFzTBGmuZX"},"source":["# Import libs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":882,"status":"ok","timestamp":1629985800143,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"zfs4eRwEmuZZ"},"outputs":[],"source":["import os\n","from threading import Thread  # for running the denoiser in parallel\n","import queue\n","\n","import numpy as np\n","import torch\n","import torch.optim\n","from models.skip import skip  # our network\n","\n","from utils.utils import *  # auxiliary functions\n","from utils.utils_mine import *\n","from utils.mine_blur_utils2 import *  \n","from utils.data import Data  # class that holds img, psnr, time\n","\n","from skimage.restoration import denoise_nl_means\n","import random \n","\n","torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)\n","\n","from scipy.signal import convolve2d\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1629985800146,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"ngzxpNsXmuZb"},"outputs":[],"source":["# got GPU? - if you are not getting the exact article results set CUDNN to False\n","CUDA_FLAG = True\n","CUDNN = True \n","if CUDA_FLAG:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    # GPU accelerated functionality for common operations in deep neural nets\n","    torch.backends.cudnn.enabled = CUDNN\n","    # benchmark mode is good whenever your input sizes for your network do not vary.\n","    # This way, cudnn will look for the optimal set of algorithms for that particular \n","    # configuration (which takes some time). This usually leads to faster runtime.\n","    # But if your input sizes changes at each iteration, then cudnn will benchmark every\n","    # time a new size appears, possibly leading to worse runtime performances.\n","    torch.backends.cudnn.benchmark = CUDNN\n","    # torch.backends.cudnn.deterministic = True\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor"]},{"cell_type":"markdown","metadata":{"id":"qn-zwXGPmuZd"},"source":["# CONSTANCTS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1629985800148,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"lMmxGWHomuZe"},"outputs":[],"source":["NOISE_SIGMA = 5 #2**.5  # sqrt(2), I haven't tests other options\n","STD_BLUR    = 1.6\n","DIM_FILTER  = 21\n","BLUR_TYPE = 'gauss_blur'  # 'gauss_blur' or 'uniform_blur' that the two only options\n","GRAY_SCALE = False  # if gray scale is False means we have rgb image, the psnr will be compared on Y. ch.\n","                    # if gray scale is True it will turn rgb to gray scale\n","USE_FOURIER = False\n","\n","# graphs labels:\n","X_LABELS = ['Iterations']*3\n","Y_LABELS = ['PSNR between x and net (db)', 'PSNR with original image (db)', 'loss']\n","\n","# Algorithm NAMES (to get the relevant image: use data_dict[alg_name].img)\n","# for example use data_dict['Clean'].img to get the clean image\n","ORIGINAL = 'Clean'\n","CORRUPTED = 'Blurred'\n","NLM = 'NLM'\n","DIP_NLM = 'DIP-WTV'"]},{"cell_type":"markdown","metadata":{"id":"TrKukM43muZf"},"source":["# Load image for Denoising"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1629985800149,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"ouHYgV4CmuZg"},"outputs":[],"source":["def load_imgs_deblurring(fname, blur_type, noise_sigma,STD_BLUR, DIM_FILTER,plot=False):\n","    \"\"\"  Loads an image, and add gaussian blur\n","    Args: \n","         fname: path to the image\n","         blur_type: 'uniform' or 'gauss'\n","         noise_sigma: noise added after blur\n","         covert2gray: should we convert to gray scale image?\n","         plot: will plot the images\n","    Out:\n","         dictionary of images and dictionary of psnrs\n","    \"\"\"\n","    img_pil, img_np = load_and_crop_image(fname)        \n","    if GRAY_SCALE:\n","        img_np = rgb2gray(img_pil)\n","    kernel = get_h(blur_type,STD_BLUR,DIM_FILTER)\n","    kernel_torch = np_to_torch(kernel)  \n","    blurred = torch_to_np(blur_th(np_to_torch(img_np), kernel_torch))\n","    blurred = np.clip(blurred + np.random.normal(scale=noise_sigma/255., size=blurred.shape), 0, 1).astype(np.float32)\n","    data_dict = { ORIGINAL: Data(img_np), \n","                 CORRUPTED: Data(blurred, compare_PSNR(img_np, blurred,   on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)) }\n","    if plot:\n","        plot_dict(data_dict)\n","    return data_dict,kernel_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":970},"executionInfo":{"elapsed":3918,"status":"ok","timestamp":1629985804053,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"hnDJbDN3muZj","outputId":"533f570e-2291-4dbc-e96c-f18f8e57c8ff"},"outputs":[],"source":["# load the image and add noise - for real use send same image file to fclean and fnoisy and ignore psnrs\n","data_dict,kernel_torch = load_imgs_deblurring('datasets/watercastle.png', BLUR_TYPE, NOISE_SIGMA,STD_BLUR, DIM_FILTER, plot=True)"]},{"cell_type":"markdown","metadata":{"id":"RuPBpXNLZRkL"},"source":["#  ESTIMATING THE NOISE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1629985804057,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"mzhtDmnIZMN1","outputId":"c5127974-ef85-4750-c775-4f45342a140b"},"outputs":[],"source":["lap_kernel = np.array([[1,-2,1], [-2, 4, -2], [1,-2,1]])\n","h=data_dict[CORRUPTED].img[:,:,:].shape[2]\n","w=data_dict[CORRUPTED].img[:,:,:].shape[1]\n","\n","def estimate_variance(img):\n","  out = convolve2d(img, lap_kernel, mode='valid')\n","  out = np.sum(np.abs(out))\n","  out = (out*np.sqrt(0.5*np.pi)/(6*(h-2)*(w-2)))\n","  return out\n","\n","print(data_dict[CORRUPTED].img[:,:,:].shape)\n","NOISE_SIGMA = estimate_variance(data_dict[CORRUPTED].img[0,:,:])*255\n","print(NOISE_SIGMA)"]},{"cell_type":"markdown","metadata":{"id":"5teVFdjUmuZk"},"source":["# THE NETWORK"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1629985804059,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"qaBXQfjTmuZl"},"outputs":[],"source":["def get_network_and_input(img_shape, input_depth=32, pad='reflection',\n","                          upsample_mode='bilinear', use_interpolate=True, align_corners=False,\n","                          act_fun='LeakyReLU', skip_n33d=[16,32,64,128,128], skip_n33u=[16,32,64,128,128], skip_n11=4,\n","                          num_scales=5, downsample_mode='stride', INPUT='noise'):  # 'meshgrid'\n","    \"\"\" Getting the relevant network and network input (based on the image shape and input depth)\n","        We are using the same default params as in DIP article\n","        img_shape - the image shape (ch, x, y)\n","    \"\"\"\n","    n_channels = img_shape[0]\n","    net = skip(input_depth, n_channels,\n","               num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n","               num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n","               num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n","               upsample_mode=upsample_mode, use_interpolate=use_interpolate, align_corners=align_corners,\n","               downsample_mode=downsample_mode, need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun).type(dtype)\n","    net_input = get_noise(input_depth, INPUT, img_shape[1:]).type(dtype).detach()\n","    return net, net_input"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":788,"status":"ok","timestamp":1629985804826,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"hmaZA4o7S8Kb"},"outputs":[],"source":["size = data_dict['Clean'].img.shape\n","h = size[-2]\n","w = size[-1]\n","Dh_psf = np.array([ [0, 0, 0], [1, -1, 0], [0, 0, 0]])\n","Dv_psf = np.array([ [0, 1, 0], [0, -1, 0], [0, 0, 0]])\n","Id_psf = np.array([[1]])\n","\n","Id_DFT = torch.from_numpy(psf2otf(Id_psf, [h,w])).cuda()\n","Dh_DFT = torch.from_numpy(psf2otf(Dh_psf, [h,w])).cuda()\n","Dv_DFT = torch.from_numpy(psf2otf(Dv_psf, [h,w])).cuda()\n","\n","DhT_DFT = torch.conj(Dh_DFT)\n","DvT_DFT = torch.conj(Dv_DFT)"]},{"cell_type":"markdown","metadata":{"id":"H4lrQq72muZq"},"source":["# Deep Image prior via ADMM with weighted TV"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":279,"status":"ok","timestamp":1629988438441,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"sxvDmRxkmuZr"},"outputs":[],"source":["def train_via_admm(net, net_input, kernel_torch,y,  noise_lev,tau, org_img=None,                      # y is the noisy image\n","                   plot_array={}, algorithm_name=\"\", admm_iter=5000, save_path=\"\",           # path to save params\n","                   LR=0.001,                                                                      # learning rate\n","                   mu=0.0008, LR_x=None, noise_factor=0.033,        #0.033  LR_x needed only if method!=fixed_point\n","                   threshold=40, threshold_step=0.01, increase_reg=0.033):                # increase regularization \n","    \"\"\" training the network using\n","        ## Must Params ##\n","        net                 - the network to be trained\n","        net_input           - the network input\n","        denoiser_function   - an external denoiser function, used as black box, this function\n","                              must get numpy noisy image, and return numpy denoised image\n","        y                   - the noisy image\n","        sigma               - the noise level (int 0-255)\n","        \n","        # optional params #\n","        org_img             - the original image if exist for psnr compare only, or None (default)\n","        plot_array          - prints params at the begging of the training and plot images at the required indices\n","        admm_iter           - total number of admm epoch\n","        LR                  - the lr of the network in admm (step 2)\n","        sigma_f             - the sigma to send the denoiser function\n","        update_iter         - denoised image updated every 'update_iter' iteration\n","        method              - 'fixed_point' or 'grad' or 'mixed' \n","        algorithm_name      - the name that would show up while running, just to know what we are running ;)\n","                \n","        # equation params #  \n","        beta                - regularization parameter (lambda in the article)\n","        mu                  - ADMM parameter\n","        LR_x                - learning rate of the parameter x, needed only if method!=fixed point\n","        # more\n","        noise_factor       - the amount of noise added to the input of the network\n","        threshold          - when the image become close to the noisy image at this psnr\n","        increase_reg       - we going to increase regularization by this amount\n","        threshold_step     - and keep increasing it every step\n","    \"\"\"\n","    # To print\n","    list_psnr=[]\n","    list_stopping=[]\n","\n","    # get optimizer and loss function:\n","    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss\n","    # additional noise added to the input:\n","    net_input_saved = net_input.detach().clone()\n","    noise = net_input.detach().clone()\n","    if org_img is not None: \n","        psnr_y = compare_PSNR(org_img, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)  # get the noisy image psnr\n","    # optimizer and scheduler\n","    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt\n","    \n","    y_torch = np_to_torch(y).type(dtype)\n","    x, mu_h, mu_v = y.copy(), np.zeros_like(y), np.zeros_like(y)\n","    t_h, t_v = np.zeros_like(y), np.zeros_like(y)\n","    f_x, avg, avg2, avg3 = x.copy(), np.rint(y), np.rint(y), np.rint(y)\n","    img_queue = queue.Queue()\n","    \n","    #inner_iter=1\n","\n","    for i in range(1, 1 + admm_iter):\n","        \n","      rho = tau*noise_lev*np.sqrt(y.shape[0]*y.shape[1]*y.shape[2] - 1)\n","\n","      # step 1, update network:\n","      optimizer.zero_grad()\n","      net_input = net_input_saved + (noise.normal_() * noise_factor)\n","      out = net(net_input)\n","      out_np = torch_to_np(out)\n","              \n","      # loss:\n","      [Dh_out, Dv_out] = D(out, Dh_DFT, Dv_DFT) #computing the gradient\n","      Dh_out_np        = torch_to_np(Dh_out)\n","      Dv_out_np        = torch_to_np(Dv_out)\n","      loss_y = mse(blur_th(out, kernel_torch), y_torch)\n","      loss_x = mse(Dh_out.type(dtype), np_to_torch(t_h - mu_h).type(dtype)) + mse(Dv_out.type(dtype), np_to_torch(t_v - mu_v).type(dtype))\n","      total_loss = loss_y + mu * loss_x\n","      total_loss.backward()\n","      optimizer.step()\n","          \n","      # step 2, update x using a denoiser and result from step 1 \n","      q_h                 = Dh_out_np + mu_h\n","      q_v                 = Dv_out_np + mu_v\n","      q_norm              = np.sqrt(np.power(q_h,2) + np.power(q_v,2))\n","      weight              = np.divide(np.power(np.linalg.norm(out_np-y),2)/(6*h*w),q_norm)\n","      q_norm[q_norm == 0] = weight[q_norm == 0]/mu\n","      q_norm              = np.clip(q_norm - weight/mu , 0, q_norm - weight/mu)/q_norm\n","      t_h                 = (q_norm*q_h)\n","      t_v                 = (q_norm*q_v)\n","\n","      np.clip(t_h, -1, 1, out=t_h)\n","      np.clip(t_v, -1, 1, out=t_v)\n","\n","      # step 3, update u\n","      mu_h = (mu_h + (Dh_out_np - t_h))\n","      mu_v = (mu_v + (Dv_out_np - t_v))\n","\n","      # Averaging:\n","      avg = avg * .99 + out_np * .01\n","\n","      stopping = np.sqrt(np.sum(np.square(torch_to_np(blur_th(out.data, kernel_torch))-y)))/ rho \n","      list_stopping.append(stopping)\n","        \n","      # show psnrs: \n","      psnr_noisy = compare_PSNR(out_np, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","        \n","      if psnr_noisy > threshold:\n","          mu = mu + increase_reg\n","          threshold += threshold_step\n","        \n","      if org_img is not None:\n","          psnr_net, psnr_avg = compare_PSNR(org_img, out_np,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE), compare_PSNR(org_img, avg, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","          list_psnr.append(psnr_avg)\n","          print('\\r', algorithm_name, '%04d/%04d Loss %f' % (i, admm_iter, total_loss.item()),\n","                  'psnrs: y: %.2f psnr_noisy: %.2f net: %.2f avg: %.2f' % (psnr_y, psnr_noisy, psnr_net, psnr_avg), \n","                  'params: stopping: %.2f' %(stopping), end='')\n","          if i in plot_array:  # plot images\n","              tmp_dict = {'Clean': Data(org_img),\n","                          'Noisy': Data(y, psnr_y),\n","                          'Net': Data(out_np, psnr_net),\n","                          'avg': Data(avg, psnr_avg),\n","                          }\n","              plot_dict(tmp_dict)\n","      else:\n","          print('\\r', algorithm_name, 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')\n","  \n","    return avg,list_psnr,list_stopping"]},{"cell_type":"markdown","metadata":{"id":"xCGuOYzfmuZ2"},"source":["## Let's Go:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":564325,"status":"ok","timestamp":1629989005587,"user":{"displayName":"PRIMO GROUP","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjzLI-IkIOKIX3Z_M4kvG55QbYC-O5s4DxmH1uc=s64","userId":"03582448591020050891"},"user_tz":-120},"id":"JYLWve6jmuaB","outputId":"5c45330e-768c-4a4a-ff24-6cf55b303459"},"outputs":[],"source":["def run_and_plot(name, plot_checkpoints={}):\n","    global data_dict\n","    noise_lev = NOISE_SIGMA/255\n","    tau=1 #lasciare a 1 se ci si fida della stima del rumore fatta dalla funzione considerata\n","    net, net_input = get_network_and_input(img_shape=data_dict[CORRUPTED].img.shape)\n","    denoised_img,list_psnr,list_stopping = train_via_admm(net, net_input, kernel_torch,data_dict[CORRUPTED].img, noise_lev,tau,\n","                                  plot_array=plot_checkpoints, algorithm_name=name,\n","                                  org_img=data_dict[ORIGINAL].img)\n","    data_dict[name] = Data(denoised_img, compare_PSNR(data_dict[ORIGINAL].img, denoised_img,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n","    plot_dict(data_dict)\n","\n","    return denoised_img,list_psnr,list_stopping\n","\n","\n","plot_checkpoints = {1, 10, 50, 100, 250, 500, 2000, 3500, 5000} \n","denoised_img,list_psnr,list_stopping=run_and_plot(DIP_NLM, plot_checkpoints)  # you may try it with different denoisers"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"deblurring_DIPWTV.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('PsiDONet22')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"2e600517162b2d52f2381e9f8081dec209e7747d3e7da5b473d1484e44801cd5"}}},"nbformat":4,"nbformat_minor":0}
