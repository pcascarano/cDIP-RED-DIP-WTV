{"cells":[{"cell_type":"markdown","metadata":{"id":"6rQlzjabmuZI"},"source":["# **Denoising DIP**\n","\n","---\n","\n","This code is mainly based on DeepRED code available at https://github.com/GaryMataev/DeepRED removing the regularization term"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1101,"status":"ok","timestamp":1631625713531,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"zfs4eRwEmuZZ"},"outputs":[],"source":["import os\n","from threading import Thread  # for running the denoiser in parallel\n","import queue\n","\n","import numpy as np\n","import torch\n","import torch.optim\n","from models.skip import skip  # our network\n","\n","from utils.utils import *  \n","from utils.data import Data  # class that holds img, psnr, time\n","\n","from skimage.restoration import denoise_nl_means\n","import random \n","from scipy.signal import convolve2d\n","\n","torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1631625713532,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"ngzxpNsXmuZb"},"outputs":[],"source":["# got GPU? - if you are not getting the exact article results set CUDNN to False\n","CUDA_FLAG = True\n","CUDNN = True \n","if CUDA_FLAG:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    # GPU accelerated functionality for common operations in deep neural nets\n","    torch.backends.cudnn.enabled = CUDNN\n","    # benchmark mode is good whenever your input sizes for your network do not vary.\n","    # This way, cudnn will look for the optimal set of algorithms for that particular \n","    # configuration (which takes some time). This usually leads to faster runtime.\n","    # But if your input sizes changes at each iteration, then cudnn will benchmark every\n","    # time a new size appears, possibly leading to worse runtime performances.\n","    torch.backends.cudnn.benchmark = CUDNN\n","    # torch.backends.cudnn.deterministic = True\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor"]},{"cell_type":"markdown","metadata":{"id":"qn-zwXGPmuZd"},"source":["# CONSTANCTS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1631625713534,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"lMmxGWHomuZe"},"outputs":[],"source":["SIGMA = 35\n","GRAY_SCALE = False\n","# graphs labels:\n","X_LABELS = ['Iterations']*3\n","Y_LABELS = ['PSNR between x and net (db)', 'PSNR with original image (db)', 'loss']\n","\n","# Algorithm NAMES (to get the relevant image: use data_dict[alg_name].img)\n","# for example use data_dict['Clean'].img to get the clean image\n","ORIGINAL = 'Clean'\n","CORRUPTED = 'Noisy'\n","NLM = 'NLM'\n","DIP_NLM = 'DIP'"]},{"cell_type":"markdown","metadata":{"id":"TrKukM43muZf"},"source":["# Load image for Denoising"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1631625713535,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"ouHYgV4CmuZg"},"outputs":[],"source":["def load_image(fclean, fnoisy=None, sigma=25, plot=False):\n","    \"\"\" \n","        fname - input file name\n","        d - Make dimensions divisible by `d`\n","        sigma - the amount of noise you want to add noise to the image\n","        Return a numpy image, and a noisy numpy image with sigma selected\n","    \"\"\"\n","    _, img_np = load_and_crop_image(fclean)\n","    if fnoisy is None:\n","        img_noisy_np = np.clip(img_np + np.random.normal(scale=sigma / 255., size=img_np.shape), 0, 1).astype(\n","            np.float32)\n","        # img_noisy_np = pil_to_np(np_to_pil(img_noisy_np)) # making it an image then loading it back to numpy\n","    else:\n","        _, img_noisy_np = load_and_crop_image(fnoisy)\n","    data_dict = {ORIGINAL: Data(img_np), CORRUPTED: Data(img_noisy_np, compare_PSNR(img_np, img_noisy_np,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))}\n","    if plot:\n","        plot_dict(data_dict)\n","    return data_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713},"executionInfo":{"elapsed":2158,"status":"ok","timestamp":1631625715675,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"hnDJbDN3muZj","outputId":"4279e9c3-d21e-4c4e-fc04-90cb29f847c0"},"outputs":[],"source":["# load the image and add noise - for real use send same image file to fclean and fnoisy and ignore psnrs\n","data_dict = load_image('datasets/Set5/bird_GT.bmp', sigma=SIGMA, plot=True)"]},{"cell_type":"markdown","metadata":{"id":"MBsebM7Fh4NB"},"source":["#  ESTIMATING THE NOISE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1631625715679,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"1JxOn9Jwh1-Z","outputId":"555547c3-37d6-451c-b1ff-b00217a444b4"},"outputs":[],"source":["lap_kernel = np.array([[1,-2,1], [-2, 4, -2], [1,-2,1]])\n","h=data_dict[CORRUPTED].img[:,:,:].shape[2]\n","w=data_dict[CORRUPTED].img[:,:,:].shape[1]\n","\n","def estimate_variance(img):\n","  out = convolve2d(img, lap_kernel, mode='valid')\n","  out = np.sum(np.abs(out))\n","  out = (out*np.sqrt(0.5*np.pi)/(6*(h-2)*(w-2)))\n","  return out\n","\n","print(data_dict[CORRUPTED].img[:,:,:].shape)\n","NOISE_SIGMA = estimate_variance(data_dict[CORRUPTED].img[0,:,:])*255\n","print(NOISE_SIGMA)"]},{"cell_type":"markdown","metadata":{"id":"5teVFdjUmuZk"},"source":["# THE NETWORK"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1631625715681,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"qaBXQfjTmuZl"},"outputs":[],"source":["def get_network_and_input(img_shape, input_depth=32, pad='reflection',\n","                          upsample_mode='bilinear', use_interpolate=True, align_corners=False,\n","                          act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128, skip_n11=4,\n","                          num_scales=5, downsample_mode='stride', INPUT='noise'):  # 'meshgrid'\n","    \"\"\" Getting the relevant network and network input (based on the image shape and input depth)\n","        We are using the same default params as in DIP article\n","        img_shape - the image shape (ch, x, y)\n","    \"\"\"\n","    n_channels = img_shape[0]\n","    net = skip(input_depth, n_channels,\n","               num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n","               num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n","               num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n","               upsample_mode=upsample_mode, use_interpolate=use_interpolate, align_corners=align_corners,\n","               downsample_mode=downsample_mode, need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun).type(dtype)\n","    net_input = get_noise(input_depth, INPUT, img_shape[1:]).type(dtype).detach()\n","    return net, net_input"]},{"cell_type":"markdown","metadata":{"id":"H4lrQq72muZq"},"source":["# Deep Image Prior"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":460,"status":"ok","timestamp":1631625716114,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"sxvDmRxkmuZr"},"outputs":[],"source":["def train_via_admm(net, net_input, y, tau,noise_lev,org_img=None,                     \n","                   plot_array={}, algorithm_name=\"\", admm_iter=2000, save_path=\"\",           \n","                   LR=0.001, noise_factor=0.033):             \n","    \n","    \"\"\" training the network using\n","        ## Must Params ##\n","        net                 - the network to be trained\n","        net_input           - the network input\n","        y                   - the noisy image\n","        sigma               - the noise level (int 0-255)\n","        \n","        # optional params #\n","        org_img             - the original image if exist for psnr compare only, or None (default)\n","        plot_array          - prints params at the begging of the training and plot images at the required indices\n","        admm_iter           - total number of admm epoch\n","        LR                  - the lr of the network in admm (step 2)\n","        sigma_f             - the sigma to send the denoiser function\n","        update_iter         - denoised image updated every 'update_iter' iteration\n","        method              - 'fixed_point' or 'grad' or 'mixed' \n","        algorithm_name      - the name that would show up while running, just to know what we are running ;)\n","                \n","        # more\n","        noise_factor       - the amount of noise added to the input of the network\n","    \"\"\"\n","    # get optimizer and loss function:\n","    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss\n","    \n","    # additional noise added to the input:\n","    net_input_saved = net_input.detach().clone()\n","    noise = net_input.detach().clone()\n","    \n","    if org_img is not None:\n","        psnr_y = compare_PSNR(org_img, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)  # get the noisy image psnr\n","   \n","    \n","    # optimizer and scheduler\n","    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt\n","    \n","    y_torch = np_to_torch(y).type(dtype)\n","    avg = np.rint(y)\n","    list_psnr=[]\n","    list_stopping=[]\n","    \n","    for i in range(1, 1 + admm_iter):\n","\n","        rho = tau*noise_lev*np.sqrt(y.shape[0]*y.shape[1]*y.shape[2] - 1)  \n","        \n","        # step 1, update network:\n","        optimizer.zero_grad()\n","        net_input = net_input_saved + (noise.normal_() * noise_factor)\n","        out = net(net_input)\n","        out_np = torch_to_np(out)\n","        # loss:\n","        loss_y = mse(out, y_torch)\n","        total_loss = loss_y\n","        total_loss.backward()\n","        optimizer.step()\n","\n","        # Averaging:\n","        avg = avg * .99 + out_np * .01\n","\n","        # show psnrs:\n","        psnr_noisy = compare_PSNR(out_np, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","\n","        stopping = np.sqrt(np.sum(np.square(out_np-y)))/ rho\n","        list_stopping.append(stopping)\n","        \n","\n","        if org_img is not None:\n","            psnr_net, psnr_avg = compare_PSNR(org_img, out_np,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE), compare_PSNR(org_img, avg, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            list_psnr.append(psnr_avg)\n","            print('\\r', algorithm_name, '%04d/%04d Loss %f' % (i, admm_iter, total_loss.item()),\n","                  'psnrs: y: %.2f psnr_noisy: %.2f net: %.2f' % (psnr_y, psnr_noisy, psnr_net),\n","                  'avg: %.2f' % (psnr_avg), 'stopping: %.2f' %(stopping), end='')\n","            if i in plot_array:  # plot images\n","                tmp_dict = {'Clean': Data(org_img),\n","                            'Noisy': Data(y, psnr_y),\n","                            'Net': Data(out_np, psnr_net),\n","                            'avg': Data(avg, psnr_avg)\n","                            }\n","                plot_dict(tmp_dict)\n","        else:\n","            print('\\r', algorithm_name, 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')\n","    \n","    return avg, list_psnr,list_stopping"]},{"cell_type":"markdown","metadata":{"id":"xCGuOYzfmuZ2"},"source":["## Let's Go:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"JYLWve6jmuaB"},"outputs":[],"source":["def run_and_plot(name, plot_checkpoints={}):\n","    global data_dict\n","    noise_lev = NOISE_SIGMA/255\n","    tau=1\n","    net, net_input = get_network_and_input(img_shape=data_dict[CORRUPTED].img.shape)\n","    denoised_img, list_psnr,list_stopping = train_via_admm(net, net_input, data_dict[CORRUPTED].img, tau,noise_lev,\n","                                  plot_array=plot_checkpoints, algorithm_name=name,\n","                                  org_img=data_dict[ORIGINAL].img)\n","    data_dict[name] = Data(denoised_img, compare_PSNR(data_dict[ORIGINAL].img, denoised_img,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n","    plot_dict(data_dict)\n","\n","    return denoised_img, list_psnr,list_stopping\n","\n","\n","plot_checkpoints = {1, 10, 50, 100, 250, 500, 1000, 1200,1400,1600,1800, 2000,2200,2400,2600,2800,3000 ,3500, 5000} \n","denoised_img,list_psnr,list_stopping=run_and_plot(DIP_NLM, plot_checkpoints)  # you may try it with different denoisers"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"denoising_DIP.ipynb","version":""},"kernelspec":{"display_name":"Python 3.10.4 ('PsiDONet22')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"2e600517162b2d52f2381e9f8081dec209e7747d3e7da5b473d1484e44801cd5"}}},"nbformat":4,"nbformat_minor":0}
