{"cells":[{"cell_type":"markdown","metadata":{"id":"6rQlzjabmuZI"},"source":["# **Denosing DIPWTV**\n","\n","---\n","\n","This code is mainly based on DeepRED code available at https://github.com/GaryMataev/DeepRED changing the regularization term as in ADMM-DIPTV code available at https://github.com/sedaboni/ADMM-DIPTV "]},{"cell_type":"markdown","metadata":{"id":"whIFzTBGmuZX"},"source":["# Import libs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2775,"status":"ok","timestamp":1651507195028,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"zfs4eRwEmuZZ"},"outputs":[],"source":["import os\n","from threading import Thread  # for running the denoiser in parallel\n","import queue\n","\n","import numpy as np\n","import torch\n","import torch.optim\n","from models.skip import skip  # our network\n","\n","from utils.utils import *  # auxiliary functions\n","from utils.utils_mine import *\n","from utils.data import Data  # class that holds img, psnr, time\n","\n","from skimage.restoration import denoise_nl_means\n","import random \n","from scipy.signal import convolve2d\n","\n","torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651507195029,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"ngzxpNsXmuZb"},"outputs":[],"source":["# got GPU? - if you are not getting the exact article results set CUDNN to False\n","CUDA_FLAG = True\n","CUDNN = True \n","if CUDA_FLAG:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    # GPU accelerated functionality for common operations in deep neural nets\n","    torch.backends.cudnn.enabled = CUDNN\n","    # benchmark mode is good whenever your input sizes for your network do not vary.\n","    # This way, cudnn will look for the optimal set of algorithms for that particular \n","    # configuration (which takes some time). This usually leads to faster runtime.\n","    # But if your input sizes changes at each iteration, then cudnn will benchmark every\n","    # time a new size appears, possibly leading to worse runtime performances.\n","    torch.backends.cudnn.benchmark = CUDNN\n","    # torch.backends.cudnn.deterministic = True\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor"]},{"cell_type":"markdown","metadata":{"id":"qn-zwXGPmuZd"},"source":["# CONSTANCTS"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651507195030,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"lMmxGWHomuZe"},"outputs":[],"source":["SIGMA = 35 \n","GRAY_SCALE = False\n","\n","# graphs labels:\n","X_LABELS = ['Iterations']*3\n","Y_LABELS = ['PSNR between x and net (db)', 'PSNR with original image (db)', 'loss']\n","\n","# Algorithm NAMES (to get the relevant image: use data_dict[alg_name].img)\n","# for example use data_dict['Clean'].img to get the clean image\n","ORIGINAL = 'Clean'\n","CORRUPTED = 'Noisy'\n","NLM = 'NLM'\n","DIP_NLM = 'DRED (NLM)'"]},{"cell_type":"markdown","metadata":{"id":"TrKukM43muZf"},"source":["# Load image for Denoising"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1651507195032,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"ouHYgV4CmuZg"},"outputs":[],"source":["def load_image(fclean, fnoisy=None, sigma=25, plot=False):\n","    \"\"\" \n","        fname - input file name\n","        d - Make dimensions divisible by `d`\n","        sigma - the amount of noise you want to add noise to the image\n","        Return a numpy image, and a noisy numpy image with sigma selected\n","    \"\"\"\n","    _, img_np = load_and_crop_image(fclean)\n","    if fnoisy is None:\n","        img_noisy_np = np.clip(img_np + np.random.normal(scale=sigma / 255., size=img_np.shape), 0, 1).astype(\n","            np.float32)\n","        # img_noisy_np = pil_to_np(np_to_pil(img_noisy_np)) # making it an image then loading it back to numpy\n","    else:\n","        _, img_noisy_np = load_and_crop_image(fnoisy)\n","    data_dict = {ORIGINAL: Data(img_np), CORRUPTED: Data(img_noisy_np, compare_PSNR(img_np, img_noisy_np, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))}\n","    if plot:\n","        plot_dict(data_dict)\n","    return data_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"elapsed":3787,"status":"ok","timestamp":1651507198808,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"hnDJbDN3muZj","outputId":"19d7c358-ea37-4b1b-da23-7271af8034e2"},"outputs":[],"source":["# load the image and add noise - for real use send same image file to fclean and fnoisy and ignore psnrs\n","data_dict = load_image('datasets/Set5/bird_GT.bmp', sigma=SIGMA, plot=True)"]},{"cell_type":"markdown","metadata":{"id":"ed34TVN1J0MJ"},"source":["#  ESTIMATING THE NOISE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1651507198810,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"3qNMxVizJ2Xm","outputId":"7b7fa1a5-ef5c-4989-afd2-0f3b42a8beec"},"outputs":[],"source":["lap_kernel = np.array([[1,-2,1], [-2, 4, -2], [1,-2,1]])\n","h=data_dict[CORRUPTED].img[:,:,:].shape[2]\n","w=data_dict[CORRUPTED].img[:,:,:].shape[1]\n","\n","def estimate_variance(img):\n","  out = convolve2d(img, lap_kernel, mode='valid')\n","  out = np.sum(np.abs(out))\n","  out = (out*np.sqrt(0.5*np.pi)/(6*(h-2)*(w-2)))\n","  return out\n","\n","print(data_dict[CORRUPTED].img[:,:,:].shape)\n","NOISE_SIGMA = estimate_variance(data_dict[CORRUPTED].img[0,:,:])*255\n","print(NOISE_SIGMA)"]},{"cell_type":"markdown","metadata":{"id":"5teVFdjUmuZk"},"source":["# THE NETWORK"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1651507198811,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"qaBXQfjTmuZl"},"outputs":[],"source":["def get_network_and_input(img_shape, input_depth=32, pad='reflection',\n","                          upsample_mode='bilinear', use_interpolate=True, align_corners=False,\n","                          act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128, skip_n11=4,\n","                          num_scales=5, downsample_mode='stride', INPUT='noise'):  # 'meshgrid'\n","    \"\"\" Getting the relevant network and network input (based on the image shape and input depth)\n","        We are using the same default params as in DIP article\n","        img_shape - the image shape (ch, x, y)\n","    \"\"\"\n","    n_channels = img_shape[0]\n","    net = skip(input_depth, n_channels,\n","               num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n","               num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n","               num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n","               upsample_mode=upsample_mode, use_interpolate=use_interpolate, align_corners=align_corners,\n","               downsample_mode=downsample_mode, need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun).type(dtype)\n","    net_input = get_noise(input_depth, INPUT, img_shape[1:]).type(dtype).detach()\n","    return net, net_input"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1650,"status":"ok","timestamp":1651507200437,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"hmaZA4o7S8Kb"},"outputs":[],"source":["size = data_dict['Clean'].img.shape\n","h = size[-2]\n","w = size[-1]\n","Dh_psf = np.array([ [0, 0, 0], [1, -1, 0], [0, 0, 0]])\n","Dv_psf = np.array([ [0, 1, 0], [0, -1, 0], [0, 0, 0]])\n","Id_psf = np.array([[1]])\n","\n","Id_DFT = torch.from_numpy(psf2otf(Id_psf, [h,w])).cuda()\n","Dh_DFT = torch.from_numpy(psf2otf(Dh_psf, [h,w])).cuda()\n","Dv_DFT = torch.from_numpy(psf2otf(Dv_psf, [h,w])).cuda()\n","\n","DhT_DFT = torch.conj(Dh_DFT)\n","DvT_DFT = torch.conj(Dv_DFT)"]},{"cell_type":"markdown","metadata":{"id":"H4lrQq72muZq"},"source":["# Deep Image prior via ADMM with weighted TV"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651507200438,"user":{"displayName":"Andrea Sebastiani","userId":"08381018070201927882"},"user_tz":-120},"id":"sxvDmRxkmuZr"},"outputs":[],"source":["def train_via_admm(net, net_input, y, noise_lev,tau, org_img=None,                      # y is the noisy image\n","                   plot_array={}, algorithm_name=\"\", admm_iter=5000, save_path=\"\",           # path to save params\n","                   LR=0.001,                                                                      # learning rate\n","                   sigma_f=3, update_iter=10, method='fixed_point',   # method: 'fixed_point' or 'grad' or 'mixed' sigma_f=3\n","                   beta=1, mu=3, LR_x=None, noise_factor=0.033,        #0.033  LR_x needed only if method!=fixed_point\n","                   threshold=40, threshold_step=0.01, increase_reg=0.03):                # increase regularization \n","    \"\"\" training the network using\n","        ## Must Params ##\n","        net                 - the network to be trained\n","        net_input           - the network input\n","        denoiser_function   - an external denoiser function, used as black box, this function\n","                              must get numpy noisy image, and return numpy denoised image\n","        y                   - the noisy image\n","        sigma               - the noise level (int 0-255)\n","        \n","        # optional params #\n","        org_img             - the original image if exist for psnr compare only, or None (default)\n","        plot_array          - prints params at the begging of the training and plot images at the required indices\n","        admm_iter           - total number of admm epoch\n","        LR                  - the lr of the network in admm (step 2)\n","        sigma_f             - the sigma to send the denoiser function\n","        update_iter         - denoised image updated every 'update_iter' iteration\n","        method              - 'fixed_point' or 'grad' or 'mixed' \n","        algorithm_name      - the name that would show up while running, just to know what we are running ;)\n","                \n","        # equation params #  \n","        beta                - regularization parameter (lambda in the article)\n","        mu                  - ADMM parameter\n","        LR_x                - learning rate of the parameter x, needed only if method!=fixed point\n","        # more\n","        noise_factor       - the amount of noise added to the input of the network\n","        threshold          - when the image become close to the noisy image at this psnr\n","        increase_reg       - we going to increase regularization by this amount\n","        threshold_step     - and keep increasing it every step\n","    \"\"\"\n","    # To print\n","    list_psnr=[]\n","\n","    # get optimizer and loss function:\n","    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss\n","    # additional noise added to the input:\n","    net_input_saved = net_input.detach().clone()\n","    noise = net_input.detach().clone()\n","    if org_img is not None:\n","        psnr_y = compare_PSNR(org_img, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)  # get the noisy image psnr\n","    # optimizer and scheduler\n","    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt\n","    \n","    y_torch = np_to_torch(y).type(dtype)\n","    x, mu_h, mu_v = y.copy(), np.zeros_like(y), np.zeros_like(y)\n","    t_h, t_v = np.zeros_like(y), np.zeros_like(y)\n","    f_x, avg, avg2, avg3 = x.copy(), np.rint(y), np.rint(y), np.rint(y)\n","    img_queue = queue.Queue()\n","\n","    list_psnr=[]\n","    list_stopping=[]\n","    \n","    inner_iter=1\n","\n","    for i in range(1, 1 + admm_iter):\n","      rho = tau*noise_lev*np.sqrt(y.shape[0]*y.shape[1]*y.shape[2] - 1) \n","        \n","        # step 1, update network:\n","      for j in range(1, 1 + inner_iter):\n","        optimizer.zero_grad()\n","        net_input = net_input_saved + (noise.normal_() * noise_factor)\n","        out = net(net_input)\n","        out_np = torch_to_np(out)\n","              \n","        # loss:\n","        [Dh_out, Dv_out] = D(out, Dh_DFT, Dv_DFT) #computing the gradient\n","        Dh_out_np        = torch_to_np(Dh_out)\n","        Dv_out_np        = torch_to_np(Dv_out)\n","        loss_y = mse(out, y_torch)\n","        loss_x = mse(Dh_out.type(dtype), np_to_torch(t_h - mu_h).type(dtype)) + mse(Dv_out.type(dtype), np_to_torch(t_v - mu_v).type(dtype))\n","        total_loss = loss_y + mu * loss_x\n","        total_loss.backward()\n","        optimizer.step()\n","          \n","        # step 2, update x using a denoiser and result from step 1\n","        \n","        #if i % update_iter == 0:  # \n","        \n","      q_h                 = Dh_out_np + mu_h\n","      q_v                 = Dv_out_np + mu_v\n","      q_norm              = np.sqrt(np.sum(np.power(q_h,2) + np.power(q_v,2),keepdims = True,axis=0)) #cambiato controllare!\n","      #q_norm              = np.sqrt(np.power(q_h,2) + np.power(q_v,2)) #cambiato controllare!\n","      weight              = np.divide(np.power(np.linalg.norm(out_np-y),2)/(6*h*w),q_norm)\n","      q_norm[q_norm == 0] = weight[q_norm == 0]/mu\n","      q_norm              = np.clip(q_norm - weight/mu , 0, q_norm - weight/mu)/q_norm\n","      t_h                 = (q_norm*q_h)\n","      t_v                 = (q_norm*q_v)\n","\n","      #np.clip(t_h, -1, 1, out=t_h)\n","      #np.clip(t_v, -1, 1, out=t_v)\n","\n","      # step 3, update u\n","      mu_h = (mu_h + (Dh_out_np - t_h))\n","      mu_v = (mu_v + (Dv_out_np - t_v))\n","\n","      # Averaging:\n","      avg = avg * .99 + out_np * .01\n","      #avg = out_np\n","        \n","      # show psnrs:\n","      psnr_noisy = compare_PSNR(out_np, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","\n","      stopping = np.sqrt(np.sum(np.square(out_np-y)))/ rho \n","      list_stopping.append(stopping)\n","        \n","      if psnr_noisy > threshold:\n","          mu = mu + increase_reg\n","          beta = beta + increase_reg\n","          threshold += threshold_step\n","        \n","      if org_img is not None:\n","          psnr_net, psnr_avg = compare_PSNR(org_img, out_np,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE), compare_PSNR(org_img, avg,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","          list_psnr.append(psnr_avg)\n","          print('\\r', algorithm_name, '%04d/%04d Loss %f' % (i, admm_iter, total_loss.item()),\n","                  'psnrs: y: %.2f psnr_noisy: %.2f net: %.2f avg: %.2f' % (psnr_y, psnr_noisy, psnr_net,psnr_avg), \n","                  'stopping: %.2f' %(stopping), end='')\n","          if i in plot_array:  # plot images\n","              tmp_dict = {'Clean': Data(org_img),\n","                          'Noisy': Data(y, psnr_y),\n","                          'Net': Data(out_np, psnr_net),\n","                          'avg': Data(avg, psnr_avg),\n","                          }\n","              plot_dict(tmp_dict)\n","      else:\n","          print('\\r', algorithm_name, 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')\n","  \n","    return avg,list_psnr,list_stopping"]},{"cell_type":"markdown","metadata":{"id":"xCGuOYzfmuZ2"},"source":["## Let's Go:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JYLWve6jmuaB","outputId":"9d6c14c1-723d-4f1e-ac4d-5d97a579584d"},"outputs":[],"source":["def run_and_plot(name, plot_checkpoints={}):\n","    global data_dict\n","    noise_lev = NOISE_SIGMA/255\n","    tau=1\n","    net, net_input = get_network_and_input(img_shape=data_dict[CORRUPTED].img.shape)\n","    denoised_img,list_psnr,list_stopping = train_via_admm(net, net_input, data_dict[CORRUPTED].img,noise_lev,tau,\n","                                  plot_array=plot_checkpoints, algorithm_name=name,\n","                                  org_img=data_dict[ORIGINAL].img)\n","    data_dict[name] = Data(denoised_img, compare_PSNR(data_dict[ORIGINAL].img, denoised_img,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n","    plot_dict(data_dict)\n","\n","    return denoised_img,list_psnr,list_stopping\n","\n","\n","plot_checkpoints = {1, 10, 50, 100, 250, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000} \n","denoised_img,list_psnr,list_stopping=run_and_plot(DIP_NLM, plot_checkpoints)  # you may try it with different denoisers"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"denoising_DIPWTV.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('PsiDONet22')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"2e600517162b2d52f2381e9f8081dec209e7747d3e7da5b473d1484e44801cd5"}}},"nbformat":4,"nbformat_minor":0}
