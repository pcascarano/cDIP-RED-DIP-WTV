{"cells":[{"cell_type":"markdown","metadata":{"id":"gwxAV9V2be6W"},"source":["# **Deblurring DIP**\n","\n","---\n","\n","This code is mainly based on DeepRED code available at https://github.com/GaryMataev/DeepRED removing the regularization term"]},{"cell_type":"markdown","metadata":{"id":"L0EnVO3Cbe6a"},"source":["# Import libs"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1479,"status":"ok","timestamp":1629903163602,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"ohameJIJbe6b"},"outputs":[],"source":["import os\n","from threading import Thread  # needed since the denoiser is running in parallel\n","import queue\n","\n","import numpy as np\n","import torch\n","import torch.optim\n","from models.skip import skip  # our network\n","\n","from utils.utils import *  # auxiliary functions\n","from utils.mine_blur_utils2 import *  # blur functions\n","from utils.data import Data  # class that holds img, psnr, time\n","\n","from skimage.restoration import denoise_nl_means\n","\n","from scipy.signal import convolve2d"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1629903163603,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"WHkR4Phrbe6d"},"outputs":[],"source":["# got GPU? - if you are not getting the exact article results set CUDNN to False\n","CUDA_FLAG = True\n","CUDNN = True \n","if CUDA_FLAG:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    # GPU accelerated functionality for common operations in deep neural nets\n","    torch.backends.cudnn.enabled = CUDNN\n","    # benchmark mode is good whenever your input sizes for your network do not vary.\n","    # This way, cudnn will look for the optimal set of algorithms for that particular \n","    # configuration (which takes some time). This usually leads to faster runtime.\n","    # But if your input sizes changes at each iteration, then cudnn will benchmark every\n","    # time a new size appears, possibly leading to worse runtime performances.\n","    torch.backends.cudnn.benchmark = CUDNN\n","    # torch.backends.cudnn.deterministic = True\n","    dtype = torch.cuda.FloatTensor\n","else:\n","    dtype = torch.FloatTensor"]},{"cell_type":"markdown","metadata":{"id":"aarek5Vsbe6e"},"source":["# Constants"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1629903734061,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"H40Sa2xEbe6f"},"outputs":[],"source":["NOISE_SIGMA = 10\n","STD_BLUR    = 0.8\n","DIM_FILTER  = 11\n","BLUR_TYPE = 'gauss_blur'  # 'gauss_blur' or 'uniform_blur' that the two only options\n","GRAY_SCALE = True  # if gray scale is False means we have rgb image, the psnr will be compared on Y. ch.\n","                    # if gray scale is True it will turn rgb to gray scale\n","USE_FOURIER = False\n","\n","# graphs labels:\n","X_LABELS = ['Iterations']*3\n","Y_LABELS = ['PSNR between x and net (db)', 'PSNR with original image (db)', 'loss']\n","\n","# Algorithm NAMES (to get the relevant image: use data_dict[alg_name].img)\n","# for example use data_dict['Clean'].img to get the clean image\n","ORIGINAL  = 'Clean'\n","CORRUPTED = 'Blurred'\n","DIP_NLM   = 'DIP'"]},{"cell_type":"markdown","metadata":{"id":"22r18Xddbe6g"},"source":["# Load image for DeBlurring"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1629903736118,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"k0zWSk8Ibe6g"},"outputs":[],"source":["def load_imgs_deblurring(fname, blur_type, noise_sigma,STD_BLUR, DIM_FILTER,plot=False):\n","    \"\"\"  Loads an image, and add gaussian blur\n","    Args: \n","         fname: path to the image\n","         blur_type: 'uniform' or 'gauss'\n","         noise_sigma: noise added after blur\n","         covert2gray: should we convert to gray scale image?\n","         plot: will plot the images\n","    Out:\n","         dictionary of images and dictionary of psnrs\n","    \"\"\"\n","    img_pil, img_np = load_and_crop_image(fname)        \n","    if GRAY_SCALE:\n","        img_np = rgb2gray(img_pil)\n","    kernel = get_h(blur_type,STD_BLUR,DIM_FILTER)\n","    kernel_torch = np_to_torch(kernel)  \n","    blurred = torch_to_np(blur_th(np_to_torch(img_np), kernel_torch))\n","    blurred = np.clip(blurred + np.random.normal(scale=noise_sigma/255., size=blurred.shape), 0, 1).astype(np.float32)\n","    data_dict = { ORIGINAL: Data(img_np), \n","                 CORRUPTED: Data(blurred, compare_PSNR(img_np, blurred,   on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)) }\n","    if plot:\n","        plot_dict(data_dict)\n","    return data_dict,kernel_torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"executionInfo":{"elapsed":3817,"status":"ok","timestamp":1629903741296,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"4roj0RCvbe6h","outputId":"69c065bd-0f56-4411-b8c5-87281fdf02ce"},"outputs":[],"source":["# Get the LR and HR images\n","data_dict,kernel_torch = load_imgs_deblurring('datasets/skyscraper.jpeg', BLUR_TYPE, NOISE_SIGMA,STD_BLUR, DIM_FILTER, plot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1629903673339,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"0oRDrnpI1B4x","outputId":"168e5ee9-fc33-4816-93b3-2d07e19c3a4d"},"outputs":[],"source":["data_dict['Blurred'].img.shape"]},{"cell_type":"markdown","metadata":{"id":"8dZG_VcmCT2j"},"source":["#  ESTIMATING THE NOISE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1629903165999,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"YDp1MDXZCWXj","outputId":"0301afcb-fbe4-4330-a655-b3900b92d5a6"},"outputs":[],"source":["lap_kernel = np.array([[1,-2,1], [-2, 4, -2], [1,-2,1]])\n","h=data_dict[CORRUPTED].img[:,:,:].shape[2]\n","w=data_dict[CORRUPTED].img[:,:,:].shape[1]\n","\n","def estimate_variance(img):\n","  out = convolve2d(img, lap_kernel, mode='valid')\n","  out = np.sum(np.abs(out))\n","  out = (out*np.sqrt(0.5*np.pi)/(6*(h-2)*(w-2)))\n","  return out\n","\n","print(data_dict[CORRUPTED].img[:,:,:].shape)\n","NOISE_SIGMA = estimate_variance(data_dict[CORRUPTED].img[0,:,:])*255\n","print(NOISE_SIGMA)"]},{"cell_type":"markdown","metadata":{"id":"-AIznm_jbe6i"},"source":["# THE NETWORK"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1629903166001,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"BV2FwA0kbe6i"},"outputs":[],"source":["def get_network_and_input(img_shape, input_depth=32, pad='reflection',\n","                          upsample_mode='bilinear', use_interpolate=True, align_corners=False,\n","                          act_fun='LeakyReLU', skip_n33d=128, skip_n33u=128, skip_n11=4,\n","                          num_scales=5, downsample_mode='stride', INPUT='noise'):  # 'meshgrid'\n","    \"\"\" Getting the relevant network and network input (based on the image shape and input depth)\n","        We are using the same default params as in DIP article\n","        img_shape - the image shape (ch, x, y)\n","    \"\"\"\n","    n_channels = img_shape[0]\n","    net = skip(input_depth, n_channels,\n","               num_channels_down=[skip_n33d] * num_scales if isinstance(skip_n33d, int) else skip_n33d,\n","               num_channels_up=[skip_n33u] * num_scales if isinstance(skip_n33u, int) else skip_n33u,\n","               num_channels_skip=[skip_n11] * num_scales if isinstance(skip_n11, int) else skip_n11,\n","               upsample_mode=upsample_mode, use_interpolate=use_interpolate, align_corners=align_corners,\n","               downsample_mode=downsample_mode, need_sigmoid=True, need_bias=True, pad=pad, act_fun=act_fun).type(dtype)\n","    net_input = get_noise(input_depth, INPUT, img_shape[1:]).type(dtype).detach()\n","    return net, net_input"]},{"cell_type":"markdown","metadata":{"id":"az_90AaSbe6l"},"source":["# Deep Image Prior"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1629903166002,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"ZoE2KVtbbe6l"},"outputs":[],"source":["def train_via_admm(net, net_input, kernel_torch, y, tau, noise_lev,             \n","                   clean_img=None, plot_array={}, algorithm_name=\"\",             \n","                   save_path=\"\", admm_iter=1400, LR=0.004, noise_factor=0.01):  \n","\n","    \"\"\" training the network using\n","        ## Must Params ##\n","        net                 - the network to be trained\n","        net_input           - the network input\n","        denoiser_function   - an external denoiser function, used as black box, this function\n","                              must get numpy noisy image, and return numpy denoised image\n","        H                   - the blur kernel\n","        y                   - the blurred image\n","        \n","        # optional params #\n","        clean_img           - the original image if exist for psnr compare only, or None (default)\n","        plot_array          - prints params at the begging of the training and plot images at the required indices\n","        algorithm_name      - the name that would show up while running, just to know what we are running ;)\n","        admm_iter           - total number of admm epoch\n","        LR                  - the lr of the network\n","        sigma_f             - the sigma to send the denoiser function\n","        update_iter         - denoised image updated every 'update_iter' iteration\n","        method              - 'fixed_point' or 'grad' or 'mixed' \n","                \n","        # equation params #  \n","        beta                - regularization parameter (lambda in the article)\n","        mu                  - ADMM parameter\n","        LR_x                - learning rate of the parameter x, needed only if method!=fixed point\n","        # more\n","        noise_factor       - the amount of noise added to the input of the network\n","    \"\"\"\n","    \n","    # get optimizer and loss function:\n","    mse = torch.nn.MSELoss().type(dtype)  # using MSE loss\n","    \n","    # additional noise added to the input:\n","    net_input_saved = net_input.detach().clone()\n","    noise = net_input.detach().clone()\n","\n","    # run RED via ADMM, initialize:\n","    optimizer = torch.optim.Adam(net.parameters(), lr=LR)  # using ADAM opt\n","    y_torch = np_to_torch(y).type(dtype)\n","    avg = np.rint(y)\n","    list_psnr=[]\n","    list_stopping=[]\n","   \n","    \n","    # ADMM:\n","    for i in range(1, 1 + admm_iter):\n","\n","        rho = tau*noise_lev*np.sqrt(y.shape[0]*y.shape[1]*y.shape[2] - 1) \n","        \n","        # step 1, update network:\n","        optimizer.zero_grad()\n","        net_input = net_input_saved + (noise.normal_() * noise_factor)\n","        out = net(net_input)\n","        out_np = torch_to_np(out)\n","        # loss:\n","        loss_y = mse(blur_th(out, kernel_torch), y_torch)\n","        total_loss = loss_y \n","        total_loss.backward()\n","        optimizer.step()\n","\n","        # Averaging:\n","        avg = avg * .99 + out_np * .01\n","\n","        # show psnrs:\n","        psnr_noisy = compare_PSNR(out_np, y,on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","\n","        #stopping = np.sqrt(np.sum(np.square(out_np-y)))/ rho\n","        stopping = np.sqrt(np.sum(np.square(torch_to_np(blur_th(out.data, kernel_torch))-y)))/ rho \n","        list_stopping.append(stopping)\n","\n","        # show psnrs:\n","        if clean_img is not None:\n","            psnr_net = compare_PSNR(clean_img, out_np, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            psnr_avg = compare_PSNR(clean_img, avg, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE)\n","            list_psnr.append(psnr_avg)\n","            print('\\r', algorithm_name, '%04d/%04d Loss %f' % (i, admm_iter, total_loss.item()),\n","                  'psnrs: net: %.2f avg: %.2f' % (psnr_net, psnr_avg), 'stopping: %.2f' %(stopping), end='')\n","            if i in plot_array:  # plot images\n","              tmp_dict = {'Clean': Data(clean_img),\n","                          'Blurred': Data(y),\n","                          'Net': Data(out_np, psnr_net),\n","                          'avg': Data(avg, psnr_avg)\n","                          }\n","              plot_dict(tmp_dict)\n","        else:\n","            print('\\r', algorithm_name, 'iteration %04d/%04d Loss %f' % (i, admm_iter, total_loss.item()), end='')\n","\n","    return avg, list_psnr,list_stopping"]},{"cell_type":"markdown","metadata":{"id":"yhQ4eAijbe6m"},"source":["## Let's Go:"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":200984,"status":"ok","timestamp":1629903366963,"user":{"displayName":"Andrea Sebastiani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj38EF9BdfjKkQDUv3f1xHq6d3HRUFQL8LP1Mpg5Mo=s64","userId":"08381018070201927882"},"user_tz":-120},"id":"6tje0Pvrbe6n","outputId":"a97c41c3-fa6e-4b31-c785-f533a7179072"},"outputs":[],"source":["def run_and_plot(name, plot_checkpoints={}):\n","    global data_dict\n","    noise_lev = NOISE_SIGMA/255\n","    tau=1\n","    net, net_input = get_network_and_input(img_shape=data_dict[CORRUPTED].img.shape)\n","    clean,list_psnr,list_stopping = train_via_admm(net, net_input, kernel_torch, data_dict[CORRUPTED].img, tau, noise_lev, \n","                           algorithm_name=name, plot_array=plot_checkpoints,\n","                           clean_img=data_dict[ORIGINAL].img)\n","    data_dict[name] = Data(clean, compare_PSNR(data_dict[ORIGINAL].img, clean, on_y=(not GRAY_SCALE), gray_scale=GRAY_SCALE))\n","    plot_dict(data_dict)\n","\n","    return clean,list_psnr,list_stopping\n","\n","\n","plot_checkpoints = {1, 10, 100, 200, 400, 600,800, 1000, 1200,1400,1600,1800,2000,2200,2400,2600,2800,3000, 5000, 10000, 20000}\n","clean,list_psnr,list_stopping = run_and_plot(DIP_NLM, plot_checkpoints)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"deblurring_DIP.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('PsiDONet22')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"2e600517162b2d52f2381e9f8081dec209e7747d3e7da5b473d1484e44801cd5"}}},"nbformat":4,"nbformat_minor":0}
